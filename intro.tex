
% \section{Preliminaries}

\chapter{Introduction}


% With online accessibility of
% devices ranging from temperature control systems to baby monitors in
% this Internet of Things era, our dependence upon the Internet for
% increasingly many facets of our daily lives only continues to
% rise.

% With the ability to access a
% variety of devices online in this Internet of Things era, ranging from
% temperature control systems to baby monitors, our dependence upon the
% Internet for increasingly many facets of our daily lives only
% continues to rise. 

% As the range of Internet services that we rely upon increases, so does our reliance upon
% the Internet. 

% Talk more about how important the Internet is?

% Perhaps find a couple of recent publications that state how common IoT is becoming.

Residential Internet reliability is increasingly important as a variety of
services that we use migrate to the Internet. Internet users today can
communicate with each other, perform financial transactions, plan
their travel, and even obtain critical services such as health
monitoring~\cite{ideal-life, remote-health-elderly} and emergency
services~\cite{emergency-voip-voipfone, emergency-voip-fcc} from their
homes. Our dependence upon the Internet is rising further as more of
our home devices become connected in this Internet of Things
era. Consequently, reliable residential Internet connectivity is critical.

Broad and longitudinal measurements of users' Internet reliability can identify vulnerable networks, their
challenges and potential enhancements. For instance, weather conditions such as
thunderstorms and rain can adversely affect Internet
reliability~\cite{pingin}. Measurements can inform which areas are
particularly vulnerable to weather conditions. Comparing measurements
against other areas with similar weather conditions can provide
insights on potential enhancements: for example, areas may be less
vulnerable to rain where Internet cables run underground. Once an
enhancement is deployed, measurements can reveal if the enhancement
has resulted in improved Internet reliability.

% Talk about how Internet reliability is difficult and who is
% interested. FCC. Even ISPs (Cite the "Nevermind" paper by Nick
% Duffield which claims that ISPs are typically reactive and wait for
% customers to call). Common users.
 
The inferences from residential Internet reliability measurements can
benefit stakeholders across the board, including policymakers,
Internet Service Providers (ISPs), and residential users
themselves. Policymakers around the world have begun efforts to
measure Internet reliability~\cite{measuring-broadband-america,
measuring-broadband-canda, ofcom-uk-broadband-research,
measuring-broadband-australia}, since such measurements can drive
incentives and policies to improve reliability. ISPs can benefit from
these measurements in multiple ways. Since even large ISPs rely upon
their users to inform them of network connectivity
issues~\cite{conext10-jin}, they may be unaware of problems in their
own networks; these measurements can help ISPs recognize underyling
problems. Further, ISPs can learn about the reliability of their
competitors. Measurements of Internet reliability will also benefit
residential users, since they can take into account the reliability of
ISPs in their geographic region when purchasing Internet services.

However, we currently lack authoritative measures of residential
Internet reliability, due to several challenges associated with
obtaining such measures. 

% Measuring
% Internet reliability at the individual user level will therefore prove invaluable in assessing
% the current state of Internet connectivity and in developing future
% enhancements.

% By detecting outage events and their duration, we
% can reason about a particular user's Internet reliability and compare
% it to other users' reliability across geography, ISPs, and
% media-types.

\section{Challenges}

Obtaining authoritative measures of residential Internet reliability
is a two-step process, each of which presents challenges. 

\subsection{Measuring Internet outages broadly and accurately}

% TODO: Should I expand on "broad"? They need to be "broad" because
% reliability could be different in different places and at different
% times and in different networks. 

% TODO: Should I try convincing people that individual user
% measurement is necessary? Why not just do Trinocular?

The first step towards measuring residential Internet
reliability is to detect \emph{Internet outages}---events that prevent
users from communicating over the Internet. Since we expect outage
events to be rare, detecting them requires broad and longitudinal
measurements. Further, residential Internet outages can vary in terms of the
number of affected users. They can affect entire counties during large power
outages. They can also affect just an individual house if a fallen tree
branch damages the last-mile link. The ideal outage measurement system
would capture all Internet outage events, including individual users'
outages, in all kinds of networks.

However, measuring outages at the individual user level is
challenging. The scale of residential users in the Internet makes it
difficult to measure outages broadly and the heterogeneity of
residential networks presents problems in interpreting measurements
and detecting outages accurately.

Existing techniques that measure individual-user-level outages
tradeoff either outage measurement breadth or accuracy. Broadly,
current techniques can be
grouped into on-premises and remote probing-based, with the former
trading off breadth, and the latter, accuracy. On-premises techniques, such as
RIPE Atlas~\cite{atlas}, SamKnows~\cite{samknows}, and
BISmark~\cite{bismark-main-bib}, measure diverse aspects of
users' Internet connections, but
measure relatively few users. These techniques 
deploy dedicated hardware at user premises that continuously conduct ping,
traceroute, DNS measurements etc.; some of these
measurements can be used to infer Internet connectivity problems. Whereas hardware
based techniques have fundamental scaling difficulties owing to
manufacturing and deployment costs, hundreds of millions of
IP addresses respond to active probes~\cite{timeouts}. Since many
residences have at least one device with a public IP address ~\cite{cgn-imc16}
(typically the home router), these IP addresses can be probed
remotely, from 
vantage points under researcher control, to measure their connectivity. Thunderping~\cite{pingin} and Trinocular~\cite{trinocular} adopt this
complementary approach to outage detection: they focus upon
measuring only connectivity but do so for many users. Since these
techniques can send probes remotely from servers under their control, without requiring any user
involvement, they are able to detect outages across time
as well as across the IPv4 address space.
% However, existing techniques do
% not study latency and therefore do not identify performance
% degradation resulting from high delay.

%TODO: Tie back to heterogeity, if possible

% Though capable of measuring Internet outages broadly, I show in this dissertation that probing-based remote outage detection techniques can
% make false inferences about outages when some scenarios
% occur~\cite{timeouts, addrchange-reasons}. 

Though capable of measuring Internet outages broadly, probing-based remote outage detection techniques can
make false inferences about outages when some scenarios
occur~\cite{timeouts, addrchange-reasons}. The likelihood of
occurrence of these scenarios varies across geographic regions,
ISPs, and media type. Analyzing outages in the presence of these
confounding factors requires broad measurements of these factors in turn.
% Due to the heterogeneity of
% residential networks, these scenarios are particularly likely to occur
% in some networks, leading to 

\subsection{Analyzing reliability using measured outages}

% TODO: Come back here and ensure this is consistent with the
% description in the Intro of chapter 2. And that the text in Chater 2
% is consistent with this.

The next step towards analzying reliability is to use measured outages
to make inferences about residential Internet reliability. Inferences
can be made by employing metrics that capture outage properties. One such
metric is the rate of Internet outages over time. Another
metric is the fraction of total time accounted for by outages. 

These metrics can quantify Internet reliability along different
dimensions---such as reliability across ISPs, media-types, geographic
regions---when facing a range of conditions. Comparing Internet
reliability metrics across ISPs can help users with their choice of ISP and
can help ISPs assess their competitors. Comparing metrics across geographic
regions can help policymakers and ISPs identify problematic areas that
can benefit from more Internet infrastructure investment. Comparing
metrics for a particular group of addresses across conditions (such as
the presence of rain) can reveal the effect of the condition on
Internet reliability.

However, not all Internet outages contribute towards
(un)reliability metrics. For example, if a user voluntarily chooses to power
off their home Internet equipment, the user has an Internet outage but
this outage should not lower the user's ISP's Internet reliability. Similarly, a power
outage in an area should contribute towards lowering the reliability
of that area, but should not lower the reliability of the
ISPs whose addresses were affected. 

% TODO: Perhaps this is too ambitious.
% The ideal Internet reliability assessment system should be capable of
% categorizing detected outages by their cause. These categorized
% outages can then be used to determine Internet reliability across
% different dimensions.

However, analyzing Internet reliability using measured outages is
again challenging. First, outage measurement errors can result in
overestimating Internet reliability problems. Second, categorizing
outages by their cause is difficult. Prior work performs
outage classification mostly using sparsely available ground
truth. Turner et al. investigate router and system logs and email
archives to find different kinds of infrastructure
outages~\cite{california-fault-lines}. Banerjee et al. analyze the
outages mailing list~\cite{outages-mailing-list} to study and
categorize widespread
outages~\cite{phillipa-outages-mailing-list}. However, these
techniques rely upon incomplete datasets, since ground truth tends to
exist only for large Internet infrastructure outages. Further, the
ground truth datasets they study are biased: Turner et al. study logs only
from the CENIC network in California and the outages mailing list has
a North American bias. 

Existing techniques that study invididual user
outages have typically focused upon outage detection and have not
attempted to categorize detected outages by their likely cause. Grover
et al. point out that users in some countries are particularly likely
to power down their home Internet equipment but do not attempt further
classification of detected outages~\cite{grover2013peeking}. Shah et
al.~\cite{disco} and Bischof et al.~\cite{alwayson} use traceroutes sent from within the
home to find the hop where probes fail. While the traceroute-based
approach has the potential to categorize outages---by correlating
failures that fail at the same hop, for instance---neither technique currently
attempts to infer the real world event (like a network or power
outage) that resulted in the outage. However, analyzing the reliability of an
ISP or the reliability of a geographic area requires the
identification of outage causes, so that the appropriate subset of
them can be used in Internet reliability metrics. 



% segregate detected outages into categories
% that suggest their cause. Once outages are categorized in this
% manner, we can estimate the reliability of an ISP by considering the
% subset of outages that affected solely that ISP.

% However, measuring residential
% outages is challenging because of the scale: there are millions of
% residential links to measure. 
% Second, users can voluntarily power
% down their home Internet equipment and it is challenging to
% distinguish between voluntary user shutdowns and an outage at the last-mile link.
 
% ; even multihomed last mile links for business connectivity
% often share the same upstream hardware, representing a single point of 
% failure~\cite{twcable-business-web}. 
% Last-mile links lack the redundancy of the Internet's core;
% thus an outage of the last-mile link is likely to cut off users'
% Internet connectivity altogether.

% The second challenge is that it can be hard to distinguish
% between an outage at the last-mile link and voluntary user shutdowns
% of their Internet connections.
% We do not have a good understanding of the reliabity of Internet
% connectivity for end-users. Understanding the reliability of Internet
% connectivity for end-users requires understanding the reliability of
% the \emph{last mile link} connecting an end-user to the Internet. This
% is because the core of the Internet is designed to be redundant but
% last mile links typically are not.
%TODO: Perhaps borrow sentence from enduser.tex about business last-mile links.


% Thesis statement comments

% Older versions of thesis statement:
% \emph{For any end-host with a publicly assigned IP address that has the ability to respond to active probes, it is possible to remotely isolate accurately determine connectivity problems experienced by that end-host's last mile link.}
% \emph{For any end-host with an IP address that has the ability to
% respond to active probes, it is possible to remotely detect outages
% experienced by that end-host's last mile link.}

% Bobby's comments: Send traceroutes, but also to related addresses. What happens when all addresses change en-masse? Can we somehow identify such instances?
% Neil suggested that I should replace end-host with 'Internet accessible device'. Can I assert that a device with a public IP address is by definition Internet accessible.
% \emph{It is possible to remotely and accurately detect outages experienced by any device with a public IP address that typically responds to active probes.}

% Come up with definition of accuracy of outages.

% and use it to compare reliability across ISPs, media-types and
% geographical areas

\section{Thesis}


% My goal in this dissertation is to use probing-based techniques to
% detect outages remotely and use detected outages for
% measuring Internet reliability.
My goal in this dissertation is to develop approaches that will
address the challenges in obtaining authoritative measures of
residential Internet reliability. I work towards this goal using the
probing-based technique due to its ability to scale. In the rest of
the dissertation, I illustrate my approaches to mitigate probing-based
techniques' problems in measuring residential Internet reliability
by defending the following thesis:

\emph{It is possible to remotely and accurately detect substantial outages
  experienced by any device with a stable public IP address that typically
  responds to active probes and use these outages to compare
  reliability across ISPs, media-types and geographical areas.} 

% The common theme is that it is possible to list, measure, mitigate
% My approaches share a common theme: I list potential sources of
% error, measure them, and mitigate them

At the heart of my approaches is the insight that it is possible to: (a) list
potential sources of error, (b) measure and evaluate these sources of
error in various circumstances, and (c) use these
measurements to mitigate error. I use this insight to list and
measure the likelihood of potential errors in outage detection due
to confounding factors (such as high latency and dynamic address reassignment) across ISPs and
geographic regions. I also use this insight to list potential causes
of unrelated outages (such as users powering off their
home Internet equipment) and develop techniques to 
measure and mitigate them. %  extracting instances where the signal
% clearly outweighs the noise.

% Negate them is true in the weather-paper. Not strictly true in
% corrfails. Think about how to do this. Ahh, just use mitigate again, whatever.

\section{Contributions}

To demonstrate the thesis, I measure two confounding factors---high
latency (Chapter~\ref{cpt:timeouts}) and dynamic address reassignent
(Chapter~\ref{cpt:addr_change})---that can lead probing-based outage
detection techniques to make false outage inferences. I go on to show how
to measure Internet reliability in the presence of inference errors
and unrelated outages (Chapter~\ref{cpt:weather} and
Chapter~\ref{cpt:corrfails}). This dissertation is organized as follows:
 % I
% demonstrate that the inflation in outage rate during the presence of a
% particular challenging condition, such as during thunderstorms, 

% I make the following
% contributions:

% TODO: 
% It is possible to remotely and accurately estimate the reliability of
% an ISP's customer's device so long as the device has
% a stable public IP address that typically
%   responds to active probes

\textbf{Chapter~\ref{cpt:bg}:~~Measuring Residential Internet
  Reliability: a Primer}

I provide background on residential
Internet reliability, define terms in the thesis statement, and place
related work in context. I describe the challenges that probing-based
remote outage detection techniques will need to address to measure
residential Internet reliability. These techniques study outages by
sending active probes (such as ping's echo requests) and use probe
responses to infer outages. They assume that a response to an active
probe indicates a working path to the probed user device and that lack
of response is indicative of failure. I illustrate two scenarios where
this assumption can be invalid, leading to potentially false outage
inferences. I also show how detected outages can be used to measure
Internet reliability along different dimensions. I illustrate
scenarios where detected outages may
need to be treated differently depending upon the type of
Internet reliability being studied (ISP-level reliability,
region-level reliability etc.).
 % I
% illustrate two potential scenarios where this assumption is
% invalid---when responses are delayed beyond the prober's timeout and
% when the probed address is dynamically reassigned. I also highlight why
% Internet outages voluntarily caused by the
% residential user need to be segregated.
% I also describe the challenge that remote probing-based techniques face
% in detecting outages specifically in the last-mile.

\textbf{Chapter~\ref{cpt:timeouts}:~~Mitigating false inferences due
to early timeout} In Chapter~\ref{cpt:timeouts}, I investigate the
prevalence of delayed probe responses due to early timeout. The lack
of response to an active probe isn't always indicative of loss; for
example, when responses are delayed beyond the prober's timeout, the
response eventually arrives but the prober would never see the
response because it timed out too early. I report how commonly
responses are delayed beyond timeouts in networks around the world and
use these measurements to discuss techniques that would mitigate this problem.
% Decouple probe retransmission
% and loss. Possibly identify that only cellular guys have long delays?
% Also, this will ensure that we trigger retransmission upon high
% latency/loss and actually identify loss as loss and high latency as
% high latency.

In Chapter~\ref{ch:addr_change}, I investigate how dynamic addressing can
lead remote probing-based outage detection techniques to make false inferences about outages and techniques to
mitigate these false inferences. My approach to mitigating
these false inferences is rooted in building a model that characterizes
the probability that a dynamic address is reassigned at any point of time. I describe preliminary
work which shows the feasibility of building such a model and detail
proposed work to gather new datasets that can feed into the
model. I will ultimately use this model to find candidate stable Internet
addresses for probing.

In Section~\ref{sec:last_mile}, I discuss an approach to determine
which of the detected outages are consistent with the failure of an
ISP's operated equipment, and which outages can be attributed to other
causes such as power outages or users voluntarily shutting down their home
Internet equipment. My approach is to probe addresses that are related
to the address that is already being probed. I propose the use of multiple criteria
to find related addresses such as geography, ISP, and network
topology. I describe how we can then use simultaneous outages of these
related addresses (or the lack thereof) to categorize outages and
estimate Intrenet reliability along various dimensions.

% We show in this proposal that confounding factors can cause RODWAP
% techniques to sometimes
% infer false outages. 

% However, we argue that RODWAP techniques can
% be used for accurate outage detection by identifying and mitigating
% confounding factors. 
 % This has
% been the basis of existing active probe based techniques that detect
% loss, and thereby outage events, such as Thunderping~\cite{pingin} and
% Trinocular~\cite{quan2013trinocular}.

% In spite of , we argue that it is possible to remotely detect
% outages on the last mile link using active probes for any end-host
% with an IP address that responds to active probes.

% We investigate potential causes that
% would lead existing active probe based outage detection approaches to
% falsely infer loss and describe proposed work to mitigate detection of
% false loss in Section~\ref{sec:timeouts} and
% Section~\ref{sec:addr_change}. We also propose 

% We show in this proposal that probe-loss need not always be due to
% lossy links.


% \begin{itemize}
%   \item{\bf{False probe-loss inference due to early timeout:}} 
%     Traditionally, active probe based approaches time out probes after a few seconds. Responses that arrive after the timeout will be reported as lost. When this happens, existing techniques would confuse high delay with probe-loss.
%   \item{\bf{False probe-loss inference due to IP address change:}}
%     Consider an IP address that was previously responsive. If the host to whom that IP address was assigned changed its IP address as a result of dynamic addressing or mobility, and if the probed IP address is not reassigned to any host, then echo responses will cease to arrive and existing techniques would infer false probe-loss.
% \end{itemize}

% After analyzing causes of false probe-loss, we will investigate techniques to remove false probe-loss. Once we remove false probe-loss, we will be left with all instances of true probe-loss and probe-delays. This will give us the ability to identify that \emph{some} link on the path to the destination is experiencing connectivity problems. However, since we are specifically interested in identifying connectivity problems on the last-mile link we require another step. In this step, we will conduct TTL-limited probing from multiple vantage points to identify which link exhibits connectivity problems.

